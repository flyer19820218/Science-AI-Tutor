# ==============================
# æ›‰è‡» Â· æ¥µé€Ÿè‡ªç„¶èƒ½é‡åŸŸï¼ˆå®Œæ•´ç‰ˆï¼‰
# å¯ç›´æ¥æ•´ä»½è¤‡è£½è²¼ä¸Š
# ==============================

import streamlit as st
import google.generativeai as genai
import os, asyncio, edge_tts, re, base64, io
from PIL import Image

# ---------- å¿…è¦å¥—ä»¶æª¢æŸ¥ ----------
try:
    import fitz  # pymupdf
except ImportError:
    st.error("âŒ ç¼ºå°‘ pymupdfï¼Œè«‹å…ˆå®‰è£")
    st.stop()

# ---------- é é¢è¨­å®š ----------
st.set_page_config(
    page_title="è‡» Â· æ¥µé€Ÿè‡ªç„¶èƒ½é‡åŸŸ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------- å…¨åŸŸ CSS ----------
st.markdown("""
<style>
.stApp { background-color: #ffffff; }
html, body, p, li, h1, h2, h3 {
    font-family: 'HanziPen SC','ç¿©ç¿©é«”',sans-serif;
    color:#000;
}
.transcript-box {
    border-left: 5px solid #000;
    padding: 14px;
    margin: 12px 0;
    background: #fdfdfd;
}
</style>
""", unsafe_allow_html=True)

st.title("ğŸƒâ€â™€ï¸ è‡» Â· æ¥µé€Ÿè‡ªç„¶èƒ½é‡åŸŸ")
st.markdown("### ğŸ”¬ æ›‰è‡»è€å¸«é™ªä½ å®Œæ•´è·‘å®Œä¸€å ‚è‡ªç„¶èª²")
st.divider()

# ---------- èªéŸ³å¼•æ“ ----------
async def generate_voice_base64(text: str):
    text = text.replace("---PAGE_SEP---", " ")
    text = re.sub(r'[^\w\u4e00-\u9fff\dï¼Œã€‚ï¼ï¼Ÿã€Œã€ï½ ]', '', text)
    communicate = edge_tts.Communicate(text, "zh-TW-HsiaoChenNeural", rate="-2%")
    audio = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio += chunk["data"]
    b64 = base64.b64encode(audio).decode()
    return f"""
    <audio controls autoplay style="width:100%">
    <source src="data:audio/mp3;base64,{b64}">
    </audio>
    """

# ---------- é¡¯ç¤ºç¨¿æ¸…æ´— ----------
def clean_for_eye(text: str):
    t = text.replace('\u00a0', ' ').replace("---PAGE_SEP---", "")
    t = re.sub(r'\[\[VOICE_START\]\].*?\[\[VOICE_END\]\]', '', t, flags=re.DOTALL)
    t = t.replace("ï½ï½", "")
    return t.strip()

# ---------- å´é‚Šæ¬„ ----------
st.sidebar.title("ğŸ”‘ å•Ÿå‹•æ§åˆ¶å¡”")
user_key = st.sidebar.text_input("Google API Key", type="password")

start_page = st.sidebar.number_input("ğŸ“„ èµ·å§‹é ç¢¼", 1, 200, 1)

# ---------- Session ----------
if "started" not in st.session_state:
    st.session_state.started = False

# ---------- SYSTEM PROMPTï¼ˆé˜²ç‚¸å½ˆç‰ˆï¼‰ ----------
SYSTEM_PROMPT = r"""
ä½ æ˜¯è³‡æ·±è‡ªç„¶ç§‘å­¸è€å¸«ã€Œæ›‰è‡»ã€ã€‚

ã€å¼·åˆ¶è¼¸å‡ºæ ¼å¼ï¼ˆæ¯ä¸€é éƒ½è¦æœ‰ï¼‰ã€‘

---PAGE_SEP---

ã€çŸ¥è­˜é»ç¸½çµã€‘
è«‹ç”¨è€ƒå‰é‡é»æ¢åˆ—ã€‚

ã€æ›‰è‡»è€å¸«ä¸Šèª²é€å­—èªªæ˜ã€‘
è«‹ç”¨è€å¸«åœ¨èª²å ‚ã€Œæ…¢æ…¢è¬›è§£ã€çš„èªæ°£ï¼Œ
å®Œæ•´è§£é‡‹æ¦‚å¿µã€åœ–åƒã€å¯¦é©—æ“ä½œï¼Œ
ä¸å°‘æ–¼ 200 å­—ã€‚

ã€å¸¸è¦‹è€ƒé»æé†’ã€‘
è«‹ç”¨è€ƒè©¦å°å‘æé†’å­¸ç”Ÿã€‚

ã€éš±è—è®€éŸ³ç¨¿ã€‘
è«‹å°‡æ‰€æœ‰æœ—è®€å…§å®¹åŒ…åœ¨ä»¥ä¸‹æ¨™ç±¤ä¸­ï¼š

[[VOICE_START]]
ï¼ˆæ‰€æœ‰å­—æ¯èˆ‡æ•¸å­—å¾ŒåŠ ï½ï½ï¼ŒåŒ–å­¸å¼è½‰å£èªï¼‰
[[VOICE_END]]

âš ï¸ é¡¯ç¤ºç¨¿ä¸­ç¦æ­¢å‡ºç¾ã€Œï½ï½ã€
âš ï¸ LaTeX å¿…é ˆæ­£ç¢ºï¼Œä¾‹å¦‚ï¼š
$$2H_{2}O \\xrightarrow{é›»è§£} 2H_{2} + O_{2}$$
"""

# ---------- ä¸»æµç¨‹ ----------
if not st.session_state.started:

    st.info("ğŸ“˜ è«‹é¸æ“‡é ç¢¼å¾Œé–‹å§‹ä¸Šèª²")

    if st.button("ğŸ é–‹å§‹ä¸Šèª²"):
        if not user_key:
            st.warning("è«‹å…ˆè¼¸å…¥ API Key")
            st.stop()

        pdf_path = "data/lecture.pdf"
        if not os.path.exists(pdf_path):
            st.error("âŒ æ‰¾ä¸åˆ° PDF")
            st.stop()

        with st.spinner("æ›‰è‡»è€å¸«å‚™èª²ä¸­â€¦"):
            doc = fitz.open(pdf_path)

            images = []
            for p in range(start_page-1, min(start_page+3, len(doc))):
                pix = doc.load_page(p).get_pixmap(matrix=fitz.Matrix(2,2))
                images.append(Image.open(io.BytesIO(pix.tobytes())))

            genai.configure(api_key=user_key)
            model = genai.GenerativeModel("models/gemini-2.5-flash")
            res = model.generate_content(
                [SYSTEM_PROMPT] + images
            )

            raw = res.text.replace('\u00a0', ' ')

            voice_blocks = re.findall(
                r'\[\[VOICE_START\]\](.*?)\[\[VOICE_END\]\]',
                raw, re.DOTALL
            )
            voice_text = " ".join(voice_blocks)

            st.session_state.audio = asyncio.run(
                generate_voice_base64(voice_text)
            )
            st.session_state.text = raw
            st.session_state.images = images
            st.session_state.started = True
            st.rerun()

# ---------- ä¸Šèª²ç•«é¢ ----------
else:
    st.success("ğŸ“ æ›‰è‡»è€å¸«ä¸Šèª²ä¸­")

    st.markdown(st.session_state.audio, unsafe_allow_html=True)
    st.divider()

    parts = [
        p for p in st.session_state.text.split("---PAGE_SEP---")
        if p.strip()
    ]

    for idx, img in enumerate(st.session_state.images):
        st.image(img, use_container_width=True)

        if idx < len(parts):
            st.markdown(
                "<div class='transcript-box'><b>ğŸ“œ æ›‰è‡»è€å¸«é€å­—ç¨¿</b></div>",
                unsafe_allow_html=True
            )
            st.markdown(clean_for_eye(parts[idx]))

        st.divider()

    if st.button("ğŸ” å›åˆ°é¦–é "):
        st.session_state.started = False
        st.rerun()
